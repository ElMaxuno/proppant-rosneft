{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:44.547623Z",
     "iopub.status.busy": "2020-10-28T20:13:44.546802Z",
     "iopub.status.idle": "2020-10-28T20:13:50.866016Z",
     "shell.execute_reply": "2020-10-28T20:13:50.864809Z"
    },
    "papermill": {
     "duration": 6.335735,
     "end_time": "2020-10-28T20:13:50.866186",
     "exception": false,
     "start_time": "2020-10-28T20:13:44.530451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math, re, os\n",
    "from rosneft_utils import contest_metric,sive_diam_pan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:50.896794Z",
     "iopub.status.busy": "2020-10-28T20:13:50.895888Z",
     "iopub.status.idle": "2020-10-28T20:13:50.899026Z",
     "shell.execute_reply": "2020-10-28T20:13:50.899515Z"
    },
    "papermill": {
     "duration": 0.02144,
     "end_time": "2020-10-28T20:13:50.899639",
     "exception": false,
     "start_time": "2020-10-28T20:13:50.878199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_submit(cnt_preds, dist_preds, indices):\n",
    "    submit = []\n",
    "    for idx, cnt, dist in zip(indices, cnt_preds, dist_preds):\n",
    "        cnt = int(cnt)\n",
    "        sizes = np.random.choice(sive_diam_pan, size=cnt, p=dist / np.sum(dist))\n",
    "        submit.extend([{\n",
    "            \"ImageId\": idx,\n",
    "            \"prop_size\": sizes[i]\n",
    "        } for i in range(cnt)])\n",
    "    return pd.DataFrame.from_records(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:50.925311Z",
     "iopub.status.busy": "2020-10-28T20:13:50.924435Z",
     "iopub.status.idle": "2020-10-28T20:13:50.927900Z",
     "shell.execute_reply": "2020-10-28T20:13:50.927352Z"
    },
    "papermill": {
     "duration": 0.01772,
     "end_time": "2020-10-28T20:13:50.928019",
     "exception": false,
     "start_time": "2020-10-28T20:13:50.910299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_SIZE = [384,384]\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:50.957223Z",
     "iopub.status.busy": "2020-10-28T20:13:50.956459Z",
     "iopub.status.idle": "2020-10-28T20:13:50.968437Z",
     "shell.execute_reply": "2020-10-28T20:13:50.967723Z"
    },
    "papermill": {
     "duration": 0.029643,
     "end_time": "2020-10-28T20:13:50.968578",
     "exception": false,
     "start_time": "2020-10-28T20:13:50.938935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment \n",
    "    # variable is set. On Kaggle this is always the case.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:50.998258Z",
     "iopub.status.busy": "2020-10-28T20:13:50.997499Z",
     "iopub.status.idle": "2020-10-28T20:13:51.000590Z",
     "shell.execute_reply": "2020-10-28T20:13:51.000134Z"
    },
    "papermill": {
     "duration": 0.019536,
     "end_time": "2020-10-28T20:13:51.000679",
     "exception": false,
     "start_time": "2020-10-28T20:13:50.981143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 15\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 800\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00005\n",
    "max_lr = 0.0002\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.035919Z",
     "iopub.status.busy": "2020-10-28T20:13:51.035167Z",
     "iopub.status.idle": "2020-10-28T20:13:51.255378Z",
     "shell.execute_reply": "2020-10-28T20:13:51.256049Z"
    },
    "papermill": {
     "duration": 0.243919,
     "end_time": "2020-10-28T20:13:51.256186",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.012267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 7.013265920000002e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def lrfn(epoch):\n",
    "    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n",
    "        if epoch < rampup_epochs:\n",
    "            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "        elif epoch < rampup_epochs + sustain_epochs:\n",
    "            lr = max_lr\n",
    "        else:\n",
    "            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "        return lr\n",
    "    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, [lrfn(x) for x in rng])\n",
    "print(y[0], y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.289773Z",
     "iopub.status.busy": "2020-10-28T20:13:51.288390Z",
     "iopub.status.idle": "2020-10-28T20:13:51.290853Z",
     "shell.execute_reply": "2020-10-28T20:13:51.291363Z"
    },
    "papermill": {
     "duration": 0.021772,
     "end_time": "2020-10-28T20:13:51.291485",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.269713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.328788Z",
     "iopub.status.busy": "2020-10-28T20:13:51.327984Z",
     "iopub.status.idle": "2020-10-28T20:13:51.330962Z",
     "shell.execute_reply": "2020-10-28T20:13:51.330474Z"
    },
    "papermill": {
     "duration": 0.025159,
     "end_time": "2020-10-28T20:13:51.331058",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.305899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=TARGET_SIZE):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "#     try:\n",
    "#         if image.shape[0]>image.shape[1]:\n",
    "#             image = tf.image.transpose(image)\n",
    "#         image = tf.image.crop_to_bounding_box(image, 0, int((image.shape[1] - image.shape[0])*.75) , int(image.shape[0]), int(image.shape[0]))\n",
    "#     except TypeError:\n",
    "#         pass\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n",
    "def data_augment(image, label=None):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.366012Z",
     "iopub.status.busy": "2020-10-28T20:13:51.365194Z",
     "iopub.status.idle": "2020-10-28T20:13:51.368112Z",
     "shell.execute_reply": "2020-10-28T20:13:51.367526Z"
    },
    "papermill": {
     "duration": 0.024325,
     "end_time": "2020-10-28T20:13:51.368216",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.343891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    with strategy.scope():\n",
    "        inp1 = tf.keras.layers.Input(shape = (*TARGET_SIZE, 3), name = 'inp1')\n",
    "        pretrained_model = tf.keras.applications.MobileNetV2(weights = 'imagenet', include_top = False)\n",
    "        pretrained_model.trainable = True\n",
    "\n",
    "        x = pretrained_model(inp1, training=False)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        output = tf.keras.layers.Dense(9, activation = 'softmax')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [inp1], outputs = [output])\n",
    "\n",
    "        # opt = tfa.optimizers.SWA(opt)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'mse',\n",
    "            metrics = ['mse']\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.401255Z",
     "iopub.status.busy": "2020-10-28T20:13:51.400562Z",
     "iopub.status.idle": "2020-10-28T20:13:51.422394Z",
     "shell.execute_reply": "2020-10-28T20:13:51.423013Z"
    },
    "papermill": {
     "duration": 0.041707,
     "end_time": "2020-10-28T20:13:51.423117",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.381410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = '../input/rosneft-challenge/RPCC_train/train/'\n",
    "train = pd.read_csv('../input/rosneft-challenge/RPCC_labels.csv')\n",
    "uniques = train[-train[['16','18','20','25']].duplicated()]\n",
    "uniques = uniques[-uniques['18'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:13:51.481156Z",
     "iopub.status.busy": "2020-10-28T20:13:51.477613Z",
     "iopub.status.idle": "2020-10-28T20:41:05.319128Z",
     "shell.execute_reply": "2020-10-28T20:41:05.319634Z"
    },
    "papermill": {
     "duration": 1633.883159,
     "end_time": "2020-10-28T20:41:05.319802",
     "exception": false,
     "start_time": "2020-10-28T20:13:51.436643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "75/75 - 47s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "75/75 - 12s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "75/75 - 12s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "75/75 - 12s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "75/75 - 11s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "75/75 - 11s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "75/75 - 11s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "75/75 - 12s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "75/75 - 11s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "75/75 - 12s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "75/75 - 11s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "75/75 - 11s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "75/75 - 12s - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "75/75 - 12s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "75/75 - 12s - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "fold 0\n",
      "(0.16349471349448896, 0.03174458591511485, 0.36111990486355017)\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "74/74 - 39s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "74/74 - 11s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "74/74 - 11s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "74/74 - 11s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "74/74 - 11s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "74/74 - 11s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "74/74 - 11s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "74/74 - 11s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "74/74 - 11s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "74/74 - 11s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "74/74 - 11s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "74/74 - 11s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "74/74 - 11s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "74/74 - 11s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "74/74 - 11s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "fold 1\n",
      "(0.1369375049062297, 0.03766309286059824, 0.28584912297467685)\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "76/76 - 38s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "76/76 - 12s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "76/76 - 12s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "76/76 - 12s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "76/76 - 12s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "76/76 - 12s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "76/76 - 12s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "76/76 - 12s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "76/76 - 12s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "76/76 - 12s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "76/76 - 11s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "76/76 - 11s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "76/76 - 12s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "76/76 - 12s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "76/76 - 12s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "fold 2\n",
      "(0.16096476367932727, 0.04772312310706622, 0.33082722453771884)\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "74/74 - 39s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "74/74 - 11s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "74/74 - 11s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "74/74 - 11s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "74/74 - 11s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "74/74 - 11s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "74/74 - 11s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "74/74 - 11s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "74/74 - 11s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "74/74 - 11s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "74/74 - 11s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "74/74 - 11s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "74/74 - 12s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "74/74 - 11s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "74/74 - 11s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "fold 3\n",
      "(0.15057996676058727, 0.046979067128380264, 0.30598131620889774)\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "77/77 - 38s - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "77/77 - 12s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "77/77 - 12s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "77/77 - 12s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "77/77 - 12s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "77/77 - 12s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "77/77 - 12s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "77/77 - 12s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "77/77 - 12s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "77/77 - 12s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "77/77 - 12s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "77/77 - 12s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "77/77 - 12s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "77/77 - 12s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "77/77 - 12s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "fold 4\n",
      "(0.14386702811897037, 0.03297866515904556, 0.31019957255885755)\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=NUM_FOLDS,shuffle=True,random_state=RANDOM_STATE)\n",
    "scores = []\n",
    "for i, (train_idx,val_idx) in enumerate(folds.split(uniques)):\n",
    "\n",
    "    train_part, val_part =  uniques.loc[train_idx] , uniques.loc[val_idx] \n",
    "    train_part = pd.merge(train, train_part[['16','18','20','25']],on=['16','18','20','25'] ,how='inner')\n",
    "    val_part = pd.merge(train, val_part[['16','18','20','25']],on=['16','18','20','25'] ,how='inner')\n",
    "    train_paths = train_part.ImageId.apply(lambda x : TRAIN_FOLDER+ str(x)+'.jpg')[-train_part['18'].isna()]\n",
    "    train_labels = train_part[train.columns[7:16]][-train_part['18'].isna()]\n",
    "\n",
    "    valid_paths = val_part.ImageId.apply(lambda x : TRAIN_FOLDER+ str(x)+'.jpg')[-val_part['18'].isna()]\n",
    "    valid_labels = val_part[val_part.columns[7:16]][-val_part['18'].isna()]\n",
    "    \n",
    "    model = get_model()\n",
    "\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((train_paths, train_labels))\n",
    "        .map(decode_image, num_parallel_calls=AUTO)\n",
    "        .cache()\n",
    "        .repeat()\n",
    "        .shuffle(1024)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((valid_paths, valid_labels))\n",
    "        .map(decode_image, num_parallel_calls=AUTO)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .cache()\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "\n",
    "    history = model.fit(train_dataset,  epochs=EPOCHS  ,  steps_per_epoch=STEPS_PER_EPOCH,verbose = 2,\n",
    "                        validation_data = valid_dataset,callbacks =[lr_callback]\n",
    "    )\n",
    "    \n",
    "    validation_shit = val_part[-val_part['18'].isna()].copy()[list(val_part.columns[1:21])+['prop_count','ImageId','fraction']]\n",
    "    prediction_shit = val_part[-val_part['18'].isna()].copy()[list(val_part.columns[1:21])+['prop_count','ImageId']]\n",
    "    \n",
    "    prediction_shit[list(val_part.columns[1:21])] = prediction_shit[list(val_part.columns[1:21])].fillna(0)\n",
    "    prediction_shit[val_part.columns[7:16]]  = model.predict(valid_dataset)\n",
    "    pred_sub = get_submit(np.ones_like(prediction_shit.ImageId) *1700,    prediction_shit[list(val_part.columns[1:21])].values ,   prediction_shit.ImageId )\n",
    "    print(f'fold {i}')\n",
    "    print(contest_metric(validation_shit,pred_sub ))\n",
    "    scores.append(contest_metric(validation_shit,pred_sub ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:41:05.464338Z",
     "iopub.status.busy": "2020-10-28T20:41:05.463594Z",
     "iopub.status.idle": "2020-10-28T20:41:05.469026Z",
     "shell.execute_reply": "2020-10-28T20:41:05.468525Z"
    },
    "papermill": {
     "duration": 0.078983,
     "end_time": "2020-10-28T20:41:05.469128",
     "exception": false,
     "start_time": "2020-10-28T20:41:05.390145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16349471349448896, 0.03174458591511485, 0.36111990486355017),\n",
       " (0.1369375049062297, 0.03766309286059824, 0.28584912297467685),\n",
       " (0.16096476367932727, 0.04772312310706622, 0.33082722453771884),\n",
       " (0.15057996676058727, 0.046979067128380264, 0.30598131620889774),\n",
       " (0.14386702811897037, 0.03297866515904556, 0.31019957255885755)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:41:05.619123Z",
     "iopub.status.busy": "2020-10-28T20:41:05.617679Z",
     "iopub.status.idle": "2020-10-28T20:47:06.026796Z",
     "shell.execute_reply": "2020-10-28T20:47:06.025967Z"
    },
    "papermill": {
     "duration": 360.486742,
     "end_time": "2020-10-28T20:47:06.026911",
     "exception": false,
     "start_time": "2020-10-28T20:41:05.540169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0155 - mse: 0.0155\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.8e-05.\n",
      "Epoch 2/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0119 - mse: 0.0119\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.6e-05.\n",
      "Epoch 3/15\n",
      "94/94 [==============================] - 14s 153ms/step - loss: 0.0067 - mse: 0.0067\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000124.\n",
      "Epoch 4/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0052 - mse: 0.0052\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000162.\n",
      "Epoch 5/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0079 - mse: 0.0079\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0002.\n",
      "Epoch 6/15\n",
      "94/94 [==============================] - 14s 151ms/step - loss: 0.0073 - mse: 0.0073\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.00017.\n",
      "Epoch 7/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0060 - mse: 0.0060\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00014600000000000003.\n",
      "Epoch 8/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0051 - mse: 0.0051\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00012680000000000002.\n",
      "Epoch 9/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0042 - mse: 0.0042\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00011144000000000003.\n",
      "Epoch 10/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0043 - mse: 0.0043\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 9.915200000000003e-05.\n",
      "Epoch 11/15\n",
      "94/94 [==============================] - 14s 153ms/step - loss: 0.0039 - mse: 0.0039\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 8.932160000000002e-05.\n",
      "Epoch 12/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0039 - mse: 0.0039\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 8.145728000000002e-05.\n",
      "Epoch 13/15\n",
      "94/94 [==============================] - 14s 151ms/step - loss: 0.0037 - mse: 0.0037\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.516582400000002e-05.\n",
      "Epoch 14/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0035 - mse: 0.0035\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 7.013265920000002e-05.\n",
      "Epoch 15/15\n",
      "94/94 [==============================] - 14s 152ms/step - loss: 0.0033 - mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "train_paths = train.ImageId.apply(lambda x : TRAIN_FOLDER+ str(x)+'.jpg')[-train['18'].isna()]\n",
    "train_labels = train[train.columns[7:16]][-train['18'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_paths, train_labels))\n",
    "    .map(decode_image, num_parallel_calls=AUTO)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .shuffle(1024)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n",
    "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "\n",
    "history = model.fit(train_dataset,  epochs=EPOCHS  ,  steps_per_epoch=STEPS_PER_EPOCH,callbacks =[lr_callback]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-28T20:47:07.237709Z",
     "iopub.status.busy": "2020-10-28T20:47:07.232390Z",
     "iopub.status.idle": "2020-10-28T20:47:07.572809Z",
     "shell.execute_reply": "2020-10-28T20:47:07.571615Z"
    },
    "papermill": {
     "duration": 0.915208,
     "end_time": "2020-10-28T20:47:07.572935",
     "exception": false,
     "start_time": "2020-10-28T20:47:06.657727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights('model_count_weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 2009.678526,
   "end_time": "2020-10-28T20:47:09.860880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-28T20:13:40.182354",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
